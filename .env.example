# Reachy Claude MCP Configuration
# Copy to .env and uncomment to customize

# Data directory for database, memory, and voice models
# REACHY_CLAUDE_HOME=~/.reachy-claude

# =============================================================================
# LLM Settings (for smart sentiment analysis)
# =============================================================================
# The system auto-detects available backends: MLX -> Ollama -> keyword fallback

# MLX model (Apple Silicon only)
# REACHY_LLM_MODEL=mlx-community/Qwen2.5-1.5B-Instruct-4bit

# Ollama settings (cross-platform, requires Ollama running)
# Install: https://ollama.ai then run: ollama pull qwen2.5:1.5b
# REACHY_OLLAMA_HOST=http://localhost:11434
# REACHY_OLLAMA_MODEL=qwen2.5:1.5b

# =============================================================================
# Memory Settings (for semantic search features)
# =============================================================================
# Requires: pip install "reachy-claude-mcp[memory]" and Qdrant running

# Qdrant vector store settings
# REACHY_QDRANT_HOST=localhost
# REACHY_QDRANT_PORT=6333

# =============================================================================
# Voice Settings
# =============================================================================
# Custom Piper voice model path (optional - auto-downloads default if not set)
# REACHY_VOICE_MODEL=/path/to/custom/voice.onnx
